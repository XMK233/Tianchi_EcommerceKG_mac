{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "730d788a-50b4-4cff-8cb9-a82034af7357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/miniconda3/envs/ml12/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "正在加载数据集...\n",
      "训练数据大小: 1242550\n",
      "测试数据大小: 5000\n",
      "开发数据大小: 5000\n",
      "正在构建实体和关系映射...\n",
      "实体数量: 249746\n",
      "关系数量: 500\n",
      "正在创建图数据结构...\n",
      "正在创建RGCN模型...\n",
      "开始训练模型...\n",
      "\n",
      "Epoch 1/6 训练中...\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 15.99 GiB of which 0 bytes is free. Process 3790 has 17179869184.00 GiB memory in use. Of the allocated memory 11.68 GiB is allocated by PyTorch, and 334.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mrgcn_kg_predictor.py\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      2\u001b[39m     lines = f.read()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:626\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:614\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:282\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_dataset, graph_data, mapper, device)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:153\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(self, data)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch_geometric/nn/conv/rgcn_conv.py:267\u001b[39m, in \u001b[36mRGCNConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_type)\u001b[39m\n\u001b[32m    260\u001b[39m                 out = out + \u001b[38;5;28mself\u001b[39m.propagate(\n\u001b[32m    261\u001b[39m                     tmp,\n\u001b[32m    262\u001b[39m                     x=weight[i, x_l],\n\u001b[32m    263\u001b[39m                     edge_type_ptr=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    264\u001b[39m                     size=size,\n\u001b[32m    265\u001b[39m                 )\n\u001b[32m    266\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m                 h = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_type_ptr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    269\u001b[39m                 out = out + (h @ weight[i])\n\u001b[32m    271\u001b[39m root = \u001b[38;5;28mself\u001b[39m.root\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/torch_geometric.nn.conv.rgcn_conv_RGCNConv_propagate_x_rp4_q6.py:241\u001b[39m, in \u001b[36mpropagate\u001b[39m\u001b[34m(self, edge_index, x, edge_type_ptr, size)\u001b[39m\n\u001b[32m    232\u001b[39m             kwargs = CollectArgs(\n\u001b[32m    233\u001b[39m                 x_j=kwargs.x_j,\n\u001b[32m    234\u001b[39m                 edge_type_ptr=kwargs.edge_type_ptr,\n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m                 dim_size=hook_kwargs[\u001b[33m'\u001b[39m\u001b[33mdim_size\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    238\u001b[39m             )\n\u001b[32m    239\u001b[39m \u001b[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:594\u001b[39m, in \u001b[36mMessagePassing.aggregate\u001b[39m\u001b[34m(self, inputs, index, ptr, dim_size)\u001b[39m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maggregate\u001b[39m(\n\u001b[32m    578\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    579\u001b[39m     inputs: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    582\u001b[39m     dim_size: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    583\u001b[39m ) -> Tensor:\n\u001b[32m    584\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[32m    585\u001b[39m \u001b[33;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[32m    586\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    592\u001b[39m \u001b[33;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[32m    593\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch_geometric/experimental.py:117\u001b[39m, in \u001b[36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[33m'\u001b[39m\u001b[33mdisable_dynamic_shapes\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m required_arg \u001b[38;5;129;01min\u001b[39;00m required_args:\n\u001b[32m    120\u001b[39m         index = required_args_pos[required_arg]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:139\u001b[39m, in \u001b[36mAggregation.__call__\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index.numel() > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dim_size <= \u001b[38;5;28mint\u001b[39m(index.max()):\n\u001b[32m    136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEncountered invalid \u001b[39m\u001b[33m'\u001b[39m\u001b[33mdim_size\u001b[39m\u001b[33m'\u001b[39m\u001b[33m (got \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m                          \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m but expected \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    138\u001b[39m                          \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m>= \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(index.max())\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:131\u001b[39m, in \u001b[36mAggregation.__call__\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     dim_size = \u001b[38;5;28mint\u001b[39m(index.max()) + \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index.numel() > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch_geometric/nn/aggr/basic.py:36\u001b[39m, in \u001b[36mMeanAggregation.forward\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     34\u001b[39m             ptr: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     35\u001b[39m             dim: \u001b[38;5;28mint\u001b[39m = -\u001b[32m2\u001b[39m) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:185\u001b[39m, in \u001b[36mAggregation.reduce\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAggregation requires \u001b[39m\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to be specified\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:85\u001b[39m, in \u001b[36mscatter\u001b[39m\u001b[34m(src, index, dim, dim_size, reduce)\u001b[39m\n\u001b[32m     82\u001b[39m     index = broadcast(index, src, dim)\n\u001b[32m     83\u001b[39m     out = src.new_zeros(size).scatter_add_(dim, index, src)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# For \"min\" and \"max\" reduction, we prefer `scatter_reduce_` on CPU or\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# in case the input does not require gradients:\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mamin\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mamax\u001b[39m\u001b[33m'\u001b[39m]:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 15.99 GiB of which 0 bytes is free. Process 3790 has 17179869184.00 GiB memory in use. Of the allocated memory 11.68 GiB is allocated by PyTorch, and 334.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "with open(\"rgcn_kg_predictor.py\", \"r\") as f:\n",
    "    lines = f.read()\n",
    "exec(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f8be1e-565a-4d65-a18b-44ab018ceaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced36ee8-25a9-4c73-8698-ad3d62bc1d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b238e35-d7c5-4e2f-b3d4-b200c703ee6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c425d21b-3048-4fd6-9e12-a9594684739a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458bd06b-60c7-4a3b-8122-d18be9a6a325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0520b7-1a54-4e33-ad29-106daae87653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9404750a-7e42-44e6-b9e1-c56fad1dc188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe23a0-a9f1-4adf-a097-32f5f826dc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f83437b-302c-419f-896c-fa57d62fca36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "正在加载数据集...\n",
      "训练数据大小: 1242550\n",
      "测试数据大小: 5000\n",
      "开发数据大小: 5000\n",
      "正在构建实体和关系映射...\n",
      "实体数量: 249746\n",
      "关系数量: 500\n",
      "正在创建图数据结构...\n",
      "正在创建GraphSAGE模型...\n",
      "开始训练模型...\n",
      "\n",
      "Epoch 1/6 训练中...\n",
      "  Batch 1214/1214 - Loss: 6.0508 - Progress: 100.0%\n",
      "Epoch 1/6 - Average Loss: 57.5603 - LR: 0.001000 - Time: 73.12s\n",
      "\n",
      "Epoch 2/6 训练中...\n",
      "  Batch 1214/1214 - Loss: 1.6572 - Progress: 100.0%\n",
      "Epoch 2/6 - Average Loss: 7.9789 - LR: 0.001000 - Time: 72.84s\n",
      "\n",
      "Epoch 3/6 训练中...\n",
      "  Batch 1214/1214 - Loss: 1.2207 - Progress: 100.0%\n",
      "Epoch 3/6 - Average Loss: 4.5948 - LR: 0.001000 - Time: 72.86s\n",
      "\n",
      "Epoch 4/6 训练中...\n",
      "  Batch 1214/1214 - Loss: 1.2480 - Progress: 100.0%\n",
      "Epoch 4/6 - Average Loss: 3.4796 - LR: 0.001000 - Time: 72.72s\n",
      "\n",
      "Epoch 5/6 训练中...\n",
      "  Batch 1214/1214 - Loss: 0.4578 - Progress: 100.0%\n",
      "Epoch 5/6 - Average Loss: 2.6771 - LR: 0.001000 - Time: 72.73s\n",
      "\n",
      "Epoch 6/6 训练中...\n",
      "  Batch 1214/1214 - Loss: 0.6113 - Progress: 100.0%\n",
      "Epoch 6/6 - Average Loss: 2.1990 - LR: 0.001000 - Time: 72.78s\n",
      "\n",
      "训练完成，开始在开发集上评估模型性能...\n",
      "\n",
      "开始在开发集上评估模型...\n",
      "将评估 5000 个三元组\n",
      "  评估进度: |██████████████████████████████████████████████████| 100.0% (5000/5000)\n",
      "\n",
      "开发集评估结果:\n",
      "HITS@1: 0.0278\n",
      "HITS@3: 0.0688\n",
      "HITS@10: 0.1594\n",
      "MRR: 0.0596\n",
      "\n",
      "开始预测尾实体...\n",
      "将处理 5000 个头实体/关系对\n",
      "  预测进度: |██████████████████████████████████████████████████| 100.0% (5000/5000)\n",
      "预测结果已保存到 /mnt/d/forCoding_data/Tianchi_EcommerceKG/preprocessedData/OpenBG500_test.tsv\n",
      "任务完成！\n"
     ]
    }
   ],
   "source": [
    "with open(\"graphsage_kg_predictor.py\", \"r\") as f:\n",
    "    lines = f.read()\n",
    "exec(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10fce5b4-9ecd-4d64-9809-7df859ea659b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cuda\n",
      "正在加载数据集...\n",
      "训练数据大小: 1242550\n",
      "测试数据大小: 5000\n",
      "开发数据大小: 5000\n",
      "正在构建实体和关系映射...\n",
      "实体数量: 249746\n",
      "关系数量: 500\n",
      "正在创建图数据结构...\n",
      "正在创建GraphSAGE模型...\n",
      "开始训练模型...\n",
      "\n",
      "Epoch 1/6 训练中...\n",
      "  Batch 4854/4854 - Loss: 0.8423 - Progress: 100.0%\n",
      "Epoch 1/6 - Average Loss: 6.3123 - LR: 0.001000 - Time: 294.48s\n",
      "\n",
      "Epoch 2/6 训练中...\n",
      "  Batch 4854/4854 - Loss: 0.2411 - Progress: 100.0%\n",
      "Epoch 2/6 - Average Loss: 1.1344 - LR: 0.001000 - Time: 290.31s\n",
      "\n",
      "Epoch 3/6 训练中...\n",
      "  Batch 4854/4854 - Loss: 0.5205 - Progress: 100.0%\n",
      "Epoch 3/6 - Average Loss: 0.7548 - LR: 0.001000 - Time: 289.24s\n",
      "\n",
      "Epoch 4/6 训练中...\n",
      "  Batch 4854/4854 - Loss: 0.0000 - Progress: 100.0%\n",
      "Epoch 4/6 - Average Loss: 0.5791 - LR: 0.001000 - Time: 291.24s\n",
      "\n",
      "Epoch 5/6 训练中...\n",
      "  Batch 4854/4854 - Loss: 0.0000 - Progress: 100.0%\n",
      "Epoch 5/6 - Average Loss: 0.4968 - LR: 0.001000 - Time: 292.58s\n",
      "\n",
      "Epoch 6/6 训练中...\n",
      "  Batch 4854/4854 - Loss: 0.2708 - Progress: 100.0%\n",
      "Epoch 6/6 - Average Loss: 0.4475 - LR: 0.001000 - Time: 290.94s\n",
      "\n",
      "训练完成，开始在开发集上评估模型性能...\n",
      "\n",
      "开始在开发集上评估模型...\n",
      "将评估 5000 个三元组\n",
      "  评估进度: |██████████████████████████████████████████████████| 100.0% (5000/5000)\n",
      "\n",
      "开发集评估结果:\n",
      "HITS@1: 0.0264\n",
      "HITS@3: 0.0762\n",
      "HITS@10: 0.1754\n",
      "MRR: 0.0637\n",
      "\n",
      "开始预测尾实体...\n",
      "将处理 5000 个头实体/关系对\n",
      "  预测进度: |██████████████████████████████████████████████████| 100.0% (5000/5000)\n",
      "预测结果已保存到 /mnt/d/forCoding_data/Tianchi_EcommerceKG/preprocessedData/OpenBG500_test.tsv\n",
      "任务完成！\n"
     ]
    }
   ],
   "source": [
    "with open(\"graphsage_kg_predictor.py\", \"r\") as f:\n",
    "    lines = f.read()\n",
    "    lines = lines.replace(\"BATCH_SIZE = 1024  # 训练批次大小\", \"BATCH_SIZE = 256  # 训练批次大小\")\n",
    "exec(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf728f2-9bf4-4bb8-a6c8-34fe7742c0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
