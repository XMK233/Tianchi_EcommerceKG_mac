{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca2153c0-598e-4422-9544-dbeadb7af971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载实体文本映射: /mnt/d/forCoding_data/Tianchi_EcommerceKG/originalData/OpenBG500/OpenBG500_entity2text.tsv\n",
      "加载关系文本映射: /mnt/d/forCoding_data/Tianchi_EcommerceKG/originalData/OpenBG500/OpenBG500_relation2text.tsv\n",
      "加载完成: 249746个实体, 500个关系\n",
      "加载数据集/mnt/d/forCoding_data/Tianchi_EcommerceKG/originalData/OpenBG500/OpenBG500_train.tsv完成，共1242550个三元组\n",
      "使用并行处理生成样本数据，进程数: 8，批大小: 38829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "生成样本数据: 100%|█████████████████████████████████████████████████████████████████| 33/33 [00:35<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本数据已保存至: /mnt/d/forCoding_data/Tianchi_EcommerceKG/preprocessedData/df_sample_full.jsonl\n",
      "生成的样本数据规模: 4970200条\n",
      "\n",
      "生成的样本数据示例:\n",
      "         instruction                input                     output\n",
      "0  我们要做一些三元组的推理，这是正例    头实体是：苦荞茶，关系是：外部材质                正确的尾实体为：苦荞麦\n",
      "1  我们要做一些三元组的推理，这是负例    头实体是：苦荞茶，关系是：外部材质                错误的尾实体为：软笔头\n",
      "2  我们要做一些三元组的推理，这是负例    头实体是：苦荞茶，关系是：外部材质                错误的尾实体为：乳白色\n",
      "3  我们要做一些三元组的推理，这是负例    头实体是：苦荞茶，关系是：外部材质            错误的尾实体为：韩国3ce唇膏\n",
      "4  我们要做一些三元组的推理，这是正例  头实体是：精品三姐妹硬糕，关系是：口味  正确的尾实体为：原味硬糕850克【10包40块糕】\n"
     ]
    }
   ],
   "source": [
    "with open(\"1__gen_data.py\", \"r\") as f:\n",
    "    js = f.read()\n",
    "    exec(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76ed0c-1f24-48c7-b3cf-6892dfeddd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43148814-8122-4fbc-849f-ead27769c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ee4c6d-7f41-47c1-ade1-1cdabcd098bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA可用，将使用GPU进行训练\n",
      "GPU 0: NVIDIA GeForce RTX 4070 Ti SUPER, 显存: 15.99GB\n",
      "数据集大小: 10000\n",
      "数据集样本示例: {'instruction': '我们要做一些三元组的推理，这是正例', 'input': '头实体是：上海柜 资生堂男士焕能紧致凝霜50ml 保湿抗老化面霜，关系是：关联场景', 'output': '正确的尾实体为：擦脸'}\n",
      "Tokenized后的数据格式: ['input_ids', 'attention_mask', 'labels']\n",
      "Input IDs示例: [105332, 112446, 44991, 23305, 40027, 9370, 113272, 3837, 100346, 36556]...\n",
      "Labels示例: [105332, 112446, 44991, 23305, 40027, 9370, 113272, 3837, 100346, 36556]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 3/3 [00:28<00:00,  9.45s/it]\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: warning: librt.so.1, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: warning: libpthread.so.0, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: warning: libstdc++.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: warning: libm.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::runtime_error::~runtime_error()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__gxx_personality_v0@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::tellp()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::steady_clock::now()@GLIBCXX_3.4.19'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_replace_aux(unsigned long, unsigned long, unsigned long, char)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for bool@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_logic_error(char const*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::logic_error@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::~locale()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_end_catch@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::logic_error::~logic_error()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__si_class_type_info@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new[](unsigned long)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak_hard()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::basic_streambuf(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned short@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::resize(unsigned long, char)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char const*@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ctype<char>::_M_widen_init() const@GLIBCXX_3.4.11'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_invalid_argument(char const*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::operator=(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_free_exception@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::notify_one()@GLIBCXX_3.4.11'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::~Init()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_pure_virtual@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::flush()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__class_type_info@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_rethrow@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_fstream<char, std::char_traits<char> >::~basic_fstream()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::compare(char const*) const@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::system_clock::now()@GLIBCXX_3.4.19'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Hash_bytes(void const*, unsigned long, unsigned long)@CXXABI_1.3.5'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long long>(long long)@GLIBCXX_3.4.9'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char*@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_Prime_rehash_policy::_M_need_rehash(unsigned long, unsigned long, unsigned long) const@GLIBCXX_3.4.18'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::out_of_range@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long)@GLIBCXX_3.4.9'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::~ios_base()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::range_error::~range_error()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::~__basic_file()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_acquire@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<bool>(bool)@GLIBCXX_3.4.9'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::overflow_error@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::range_error@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_filebuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete[](void*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(unsigned long, char, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_transfer(std::__detail::_List_node_base*, std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::replace(unsigned long, unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::exception@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_M_destroy(std::allocator<wchar_t> const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream& std::istream::_M_extract<double>(double&)@GLIBCXX_3.4.9'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::basic_ifstream(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(std::string const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new(unsigned long)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::domain_error@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char, unsigned long) const@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::put(char)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for int@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_alloc()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_thread_atexit@CXXABI_1.3.7'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int*@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::~basic_ifstream()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::Init()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::condition_variable()@GLIBCXX_3.4.11'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::basic_filebuf()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::domain_error::~domain_error()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cerr@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::invalid_argument@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void*@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(std::string const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_rebalance_for_erase(std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_hook(std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_unhook()@GLIBCXX_3.4.15'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::_M_sync(char*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<char, std::char_traits<char> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `log2f@GLIBC_2.2.5'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::exception::~exception()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_create(unsigned long, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::is_open() const@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_istringstream()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::swap(std::string&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::basic_streambuf(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::init(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_cast()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::clear(std::_Ios_Iostate)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::operator=(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long*@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete(void*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(int)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_M_destroy(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<wchar_t, std::char_traits<wchar_t> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::runtime_error@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_insert_and_rebalance(bool, std::_Rb_tree_node_base*, std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_stringstream()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long>(long)@GLIBCXX_3.4.9'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::get()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long long@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::operator<< <std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::out_of_range::~out_of_range()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::length_error::~length_error()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::__ostream_insert<char, std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*, long)@GLIBCXX_3.4.9'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::invalid_argument::~invalid_argument()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::swap(std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cout@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long long>(unsigned long long)@GLIBCXX_3.4.9'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<void const*>(void const*)@GLIBCXX_3.4.9'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::underflow_error@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::out_of_range@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_allocate_exception@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void const*@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::init(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::reserve(unsigned long)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_begin_catch@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::open(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_M_sync(wchar_t*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::getline(char*, long, char)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istream<char, std::char_traits<char> >& std::getline<char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::basic_string<char, std::char_traits<char>, std::allocator<char> >&, char)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::~condition_variable()@GLIBCXX_3.4.11'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::insert(unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned char@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::ios_base()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_out_of_range(char const*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::overflow_error::~overflow_error()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_length_error(char const*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_system_error(int)@GLIBCXX_3.4.11'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ofstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<double>(double)@GLIBCXX_3.4.9'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::operator=(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long long@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(char const*, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_release@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_throw@CXXABI_1.3'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::underflow_error::~underflow_error()@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::length_error@GLIBCXX_3.4'\n",
      "/home/xiuminke/miniconda3/envs/ml12/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::~basic_filebuf()@GLIBCXX_3.4'\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n",
      "Error converting labels to tensor: only integer tensors of a single element can be converted to an index\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:223\u001b[39m, in \u001b[36mcompute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, **kwargs)\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: only integer tensors of a single element can be converted to an index",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m2.1-基于0_改进一下.py\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      2\u001b[39m     js = f.read()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:353\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/transformers/trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/transformers/trainer.py:2674\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2667\u001b[39m context = (\n\u001b[32m   2668\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2670\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2671\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2672\u001b[39m )\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2677\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2679\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2680\u001b[39m ):\n\u001b[32m   2681\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2682\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:295\u001b[39m, in \u001b[36mtraining_step\u001b[39m\u001b[34m(self, model, inputs, *args, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/transformers/trainer.py:4020\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4017\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   4019\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4020\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4022\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   4023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4024\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4025\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   4026\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:230\u001b[39m, in \u001b[36mcompute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/_tensor.py:1226\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype=dtype)\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1226\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy().astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "with open(\"2.1-基于0_改进一下.py\", \"r\") as f:\n",
    "    js = f.read()\n",
    "    exec(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21db9ed-193b-42eb-bf0f-2d7fe386a56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d98b9e-372c-49b5-870d-d1812f4d9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA可用，将使用GPU进行训练\n",
      "GPU 0: NVIDIA GeForce RTX 4070 Ti SUPER, 显存: 15.99GB\n",
      "数据集大小: 10000\n",
      "数据集样本示例: {'instruction': '我们要做一些三元组的推理，这是正例', 'input': '头实体是：上海柜 资生堂男士焕能紧致凝霜50ml 保湿抗老化面霜，关系是：关联场景', 'output': '正确的尾实体为：擦脸'}\n",
      "Tokenized后的数据格式: ['input_ids', 'attention_mask', 'labels']\n",
      "Input IDs示例: [105332, 112446, 44991, 23305, 40027, 9370, 113272, 3837, 100346, 36556]...\n",
      "Labels示例: [105332, 112446, 44991, 23305, 40027, 9370, 113272, 3837, 100346, 36556]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n",
      "Error converting labels to tensor: only integer tensors of a single element can be converted to an index\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 223\u001b[39m, in \u001b[36mCustomTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, **kwargs)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     inputs[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.to(model.device)\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mTypeError\u001b[39m: only integer tensors of a single element can be converted to an index",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 353\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# 尝试训练模型\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m开始训练...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[38;5;66;03m# 确保保存目录存在\u001b[39;00m\n\u001b[32m    356\u001b[39m save_dir = \u001b[33m\"\u001b[39m\u001b[33m/mnt/d/forCoding_data/Tianchi_EcommerceKG/trained_models/lora-ckpt/final\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/transformers/trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/transformers/trainer.py:2674\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2667\u001b[39m context = (\n\u001b[32m   2668\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2670\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2671\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2672\u001b[39m )\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2677\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2679\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2680\u001b[39m ):\n\u001b[32m   2681\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2682\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 295\u001b[39m, in \u001b[36mCustomTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, *args, **kwargs)\u001b[39m\n\u001b[32m    293\u001b[39m inputs = {k: v.to(model.device) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs.items()}\n\u001b[32m    294\u001b[39m \u001b[38;5;66;03m# 将额外的参数传递给父类方法\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/transformers/trainer.py:4020\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4017\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   4019\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4020\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4022\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   4023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4024\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4025\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   4026\u001b[39m ):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 230\u001b[39m, in \u001b[36mCustomTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, **kwargs)\u001b[39m\n\u001b[32m    227\u001b[39m         \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m    228\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    229\u001b[39m             \u001b[38;5;66;03m# 尝试将列表转换为numpy数组再转为tensor\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m             inputs[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m] = torch.tensor(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m).to(model.device)\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    232\u001b[39m     \u001b[38;5;66;03m# 确保labels在正确的设备上\u001b[39;00m\n\u001b[32m    233\u001b[39m     inputs[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m] = inputs[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m].to(model.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/torch/_tensor.py:1226\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype=dtype)\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1226\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy().astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = 'https://hf-mirror.com'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['all_proxy'] = 'socks5://127.0.0.1:7890'\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# 增加内存碎片整理配置\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# 尝试自动检测CUDA路径，如果失败则使用CPU\n",
    "import torch\n",
    "try:\n",
    "    # 尝试导入CUDA相关模块\n",
    "    has_cuda = torch.cuda.is_available()\n",
    "    if has_cuda:\n",
    "        print(\"CUDA可用，将使用GPU进行训练\")\n",
    "        # 打印GPU信息\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        for i in range(gpu_count):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)\n",
    "            print(f\"GPU {i}: {gpu_name}, 显存: {gpu_memory:.2f}GB\")\n",
    "    else:\n",
    "        print(\"CUDA不可用，将使用CPU进行训练\")\n",
    "except:\n",
    "    has_cuda = False\n",
    "    print(\"CUDA不可用，将使用CPU进行训练\")\n",
    "\n",
    "import pandas as pd, openai, random, gc\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# 配置内存优化参数\n",
    "def get_memory_optimization_args():\n",
    "    \"\"\"为16GB显存和32GB内存配置的内存优化参数\"\"\"\n",
    "    return {\n",
    "        # 根据GPU显存调整参数\n",
    "        \"max_seq_length\": 256,            # 减少序列长度节省内存\n",
    "        \"gradient_accumulation_steps\": 4,  # 减少梯度累积步数，提高GPU利用率\n",
    "        \"per_device_train_batch_size\": 4,  # 增加批量大小提高GPU利用率\n",
    "        \"gradient_checkpointing\": False,   # 禁用梯度检查点，提高训练速度\n",
    "        \"optim\": \"adamw_torch_fused\",     # 使用融合优化器加速训练\n",
    "        \"fp16\": has_cuda,                 # 启用混合精度训练\n",
    "        \"gradient_checkpointing_kwargs\": {\"use_reentrant\": False},\n",
    "        \"bf16\": False,                    # 禁用bf16（除非GPU支持且有明确收益）\n",
    "        \"use_cache\": False                # 禁用KV缓存以节省内存\n",
    "    }\n",
    "\n",
    "# 获取内存优化参数\n",
    "memory_optim_args = get_memory_optimization_args()\n",
    "\n",
    "model_path = \"/mnt/d/HuggingFaceModels\"\n",
    "# dataset = load_dataset(\n",
    "#     \"json\", \n",
    "#     data_files=\"/mnt/d/forCoding_data/Tianchi_EcommerceKG/preprocessedData/df_sample_full.jsonl\", \n",
    "#     split=\"train\"\n",
    "# )\n",
    "# 正确加载JSON Lines文件\n",
    "# 方法1：使用load_dataset的jsonl加载功能\n",
    "dataset = load_dataset(\n",
    "    \"json\", \n",
    "    data_files=\"/mnt/d/forCoding_data/Tianchi_EcommerceKG/preprocessedData/df_sample_full.jsonl\", \n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "# 确保数据集不为空\n",
    "print(f\"数据集大小: {len(dataset)}\")\n",
    "if len(dataset) == 0:\n",
    "    raise ValueError(\"数据集为空，请检查数据文件路径是否正确\")\n",
    "\n",
    "# 查看数据集的前几个样本\n",
    "sample = dataset[0]\n",
    "print(f\"数据集样本示例: {sample}\")\n",
    "\n",
    "# 加载分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-4B\", cache_dir=model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 修改数据处理函数，确保正确设置标签\n",
    "def tokenize(examples):\n",
    "    texts = [\n",
    "        f\"{inst}\\n{inp}\\n{out}\"\n",
    "        for inst, inp, out in zip(\n",
    "            examples[\"instruction\"],\n",
    "            examples[\"input\"],\n",
    "            examples[\"output\"]\n",
    "        )\n",
    "    ]\n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        max_length=memory_optim_args[\"max_seq_length\"],  # 使用优化的序列长度节省内存\n",
    "        padding=\"max_length\",  # 使用max_length填充而不是动态填充\n",
    "        return_tensors=\"pt\"  # 提前返回PyTorch张量，减少内存转换开销\n",
    "    )\n",
    "    # 正确设置labels，确保梯度能够流动\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
    "    return tokenized\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True, remove_columns=dataset.column_names)\n",
    "\n",
    "# 检查tokenized后的数据集格式\n",
    "print(f\"Tokenized后的数据格式: {list(dataset.features.keys())}\")\n",
    "# 确保在打印前将CUDA张量移至CPU\n",
    "input_ids_sample = dataset[0]['input_ids'][:10]\n",
    "labels_sample = dataset[0]['labels'][:10]\n",
    "if isinstance(input_ids_sample, torch.Tensor) and input_ids_sample.device.type == 'cuda':\n",
    "    input_ids_sample = input_ids_sample.cpu()\n",
    "labels_sample = dataset[0]['labels'][:10]\n",
    "if isinstance(labels_sample, torch.Tensor) and labels_sample.device.type == 'cuda':\n",
    "    labels_sample = labels_sample.cpu()\n",
    "print(f\"Input IDs示例: {input_ids_sample}...\")\n",
    "print(f\"Labels示例: {labels_sample}...\")\n",
    "\n",
    "# 根据实际环境选择是否使用量化\n",
    "try:\n",
    "    # 配置量化参数，适合16GB显存\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16  # 使用float16而不是bfloat16，对某些显卡更友好\n",
    "    )\n",
    "    use_quantization = True\n",
    "except Exception as e:\n",
    "    print(f\"量化配置失败: {e}\")\n",
    "    print(\"将不使用量化\")\n",
    "    use_quantization = False\n",
    "\n",
    "# 使用GPU和量化加载模型\n",
    "model_kwargs = {\n",
    "    \"cache_dir\": model_path,\n",
    "    \"torch_dtype\": torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "    \"device_map\": \"auto\" if torch.cuda.is_available() else None,\n",
    "    \"trust_remote_code\": True\n",
    "}\n",
    "\n",
    "if use_quantization:\n",
    "    model_kwargs[\"quantization_config\"] = quantization_config\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen3-4B\",\n",
    "    **model_kwargs\n",
    ")\n",
    "\n",
    "# 配置LoRA参数\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=4, lora_alpha=8, lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    bias=\"none\"  # 确保偏置不参与LoRA\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# 配置训练参数，平衡显存使用和GPU利用率\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-ckpt\",\n",
    "    per_device_train_batch_size=memory_optim_args[\"per_device_train_batch_size\"],\n",
    "    gradient_accumulation_steps=memory_optim_args[\"gradient_accumulation_steps\"],\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=memory_optim_args[\"fp16\"],\n",
    "    bf16=memory_optim_args[\"bf16\"],\n",
    "    optim=memory_optim_args[\"optim\"],\n",
    "    gradient_checkpointing=memory_optim_args[\"gradient_checkpointing\"],\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    "    # 添加以下参数解决梯度问题\n",
    "    gradient_checkpointing_kwargs=memory_optim_args[\"gradient_checkpointing_kwargs\"],\n",
    "    # 添加性能监控\n",
    "    logging_steps=10,\n",
    "    # 启用梯度裁剪防止梯度爆炸\n",
    "    max_grad_norm=1.0,\n",
    "    # 添加数据加载优化\n",
    "    dataloader_num_workers=4,  # 使用多个进程加载数据\n",
    "    dataloader_pin_memory=True,  # 固定内存以加速数据传输\n",
    "    # 启用自动批处理大小查找（如果支持）\n",
    "    auto_find_batch_size=False,\n",
    "    \n",
    ")\n",
    "\n",
    "# 优化数据加载和预处理\n",
    "def optimize_data_loader(dataset, batch_size):\n",
    "    \"\"\"优化数据加载器以提高GPU利用率\"\"\"\n",
    "    from torch.utils.data import DataLoader\n",
    "    import multiprocessing\n",
    "    \n",
    "    # 确定最佳的工作进程数\n",
    "    num_workers = min(4, multiprocessing.cpu_count() - 1)\n",
    "    \n",
    "    # 创建优化的数据加载器\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "        prefetch_factor=2  # 预加载更多批次\n",
    "    )\n",
    "    \n",
    "    return data_loader\n",
    "\n",
    "# 自定义Trainer类以确保梯度正确传播并处理额外参数\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        # 忽略DeepSpeed可能传递的额外参数，解决'num_items_in_batch'参数错误\n",
    "        # 确保inputs包含labels，并且labels是可微分的\n",
    "        if \"labels\" not in inputs:\n",
    "            raise ValueError(\"输入中缺少labels\")\n",
    "        \n",
    "        # 深度复制inputs以避免修改原始数据\n",
    "        inputs = {k: v.clone() if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
    "        \n",
    "        # 确保labels是tensor并且在正确的设备上\n",
    "        if not isinstance(inputs[\"labels\"], torch.Tensor):\n",
    "            try:\n",
    "                inputs[\"labels\"] = torch.tensor(inputs[\"labels\"]).to(model.device)\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting labels to tensor: {e}\")\n",
    "                # 如果转换失败，尝试其他处理方式\n",
    "                import numpy as np\n",
    "                if isinstance(inputs[\"labels\"], list):\n",
    "                    # 尝试将列表转换为numpy数组再转为tensor\n",
    "                    inputs[\"labels\"] = torch.tensor(np.array(inputs[\"labels\"])).to(model.device)\n",
    "        else:\n",
    "            # 确保labels在正确的设备上\n",
    "            inputs[\"labels\"] = inputs[\"labels\"].to(model.device)\n",
    "        \n",
    "        # 检查是否有其他CUDA张量需要处理（避免numpy转换错误）\n",
    "        for key, value in inputs.items():\n",
    "            if isinstance(value, torch.Tensor) and value.device.type == 'cuda':\n",
    "                # 只处理需要转换为numpy的情况，但在当前上下文中不进行转换\n",
    "                # 保留在CUDA设备上以加速计算\n",
    "                pass\n",
    "        \n",
    "        # 确保labels是整数类型\n",
    "        if inputs[\"labels\"].dtype != torch.long:\n",
    "            inputs[\"labels\"] = inputs[\"labels\"].long()\n",
    "        \n",
    "        # 检查并修复可能的索引问题\n",
    "        if inputs[\"labels\"].dim() > 1:\n",
    "            # 如果labels是多维的，确保其形状正确\n",
    "            inputs[\"labels\"] = inputs[\"labels\"].squeeze()\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # 确保loss是标量并且可以微分\n",
    "        if loss is None:\n",
    "            try:\n",
    "                # 如果模型没有自动计算loss，手动计算\n",
    "                logits = outputs.logits\n",
    "                labels = inputs[\"labels\"]\n",
    "                # 使用交叉熵损失\n",
    "                loss_fct = torch.nn.CrossEntropyLoss()\n",
    "                # 调整logits和labels的形状以匹配CrossEntropyLoss的要求\n",
    "                loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "            except Exception as e:\n",
    "                print(f\"Error computing loss: {e}\")\n",
    "                # 确保在打印前处理CUDA张量\n",
    "                logits_shape = logits.shape\n",
    "                labels_shape = labels.shape\n",
    "                print(f\"Logits shape: {logits_shape}\")\n",
    "                print(f\"Labels shape: {labels_shape}\")\n",
    "                raise\n",
    "        \n",
    "        # 定期打印GPU内存使用情况和利用率\n",
    "        if self.state.global_step % 20 == 0 and has_cuda:\n",
    "            allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "            reserved = torch.cuda.memory_reserved() / (1024**3)\n",
    "            # 尝试获取GPU利用率（需要pynvml库）\n",
    "            try:\n",
    "                import pynvml\n",
    "                pynvml.nvmlInit()\n",
    "                handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "                utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "                gpu_util = utilization.gpu\n",
    "                pynvml.nvmlShutdown()\n",
    "                print(f\"GPU内存: 已分配 {allocated:.2f}GB, 已保留 {reserved:.2f}GB | GPU利用率: {gpu_util}%\")\n",
    "            except Exception as e:\n",
    "                print(f\"GPU内存: 已分配 {allocated:.2f}GB, 已保留 {reserved:.2f}GB\")\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "        \n",
    "    def training_step(self, model, inputs, *args, **kwargs):\n",
    "        # 确保所有输入都在正确的设备上\n",
    "        inputs = {k: v.to(model.device) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
    "        # 将额外的参数传递给父类方法\n",
    "        return super().training_step(model, inputs, *args, **kwargs)\n",
    "        \n",
    "    def get_train_dataloader(self, *args, **kwargs):\n",
    "        # 覆盖默认的数据加载器创建逻辑\n",
    "        if self.train_dataset is None:\n",
    "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "        \n",
    "        # 使用我们优化的数据加载器\n",
    "        return optimize_data_loader(self.train_dataset, self.args.per_device_train_batch_size)\n",
    "\n",
    "# 优化模型和数据的设备放置\n",
    "def prepare_model_for_training(model):\n",
    "    \"\"\"优化模型以进行高效训练\"\"\"\n",
    "    # 启用CUDA图优化（如果支持）\n",
    "    if has_cuda:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True  # 允许TF32加速\n",
    "        torch.backends.cudnn.benchmark = True  # 启用cudnn自动调优\n",
    "    \n",
    "    # 确保模型在正确的设备上\n",
    "    model = model.to(model.device)\n",
    "    \n",
    "    # 设置模型为训练模式\n",
    "    model.train()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 准备模型进行训练\n",
    "model = prepare_model_for_training(model)\n",
    "\n",
    "# 使用自定义Trainer\n",
    "if torch.cuda.is_available():\n",
    "    # 在GPU上使用自定义Trainer\n",
    "    trainer = CustomTrainer(model=model, args=training_args, train_dataset=dataset)\n",
    "else:\n",
    "    # 在CPU上使用标准Trainer（可能需要调整参数以减少内存使用）\n",
    "    trainer = Trainer(model=model, args=training_args, train_dataset=dataset)\n",
    "\n",
    "# 添加定期的内存清理和性能监控\n",
    "from transformers import TrainerCallback\n",
    "def cleanup_memory():\n",
    "    \"\"\"定期清理内存以避免内存泄漏\"\"\"\n",
    "    gc.collect()\n",
    "    if has_cuda:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# 添加定期清理回调\n",
    "class MemoryCleanupCallback(TrainerCallback):\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        # 每100步清理一次内存\n",
    "        if state.global_step % 100 == 0:\n",
    "            cleanup_memory()\n",
    "\n",
    "# 添加回调到trainer\n",
    "cleanup_callback = MemoryCleanupCallback()\n",
    "trainer.add_callback(cleanup_callback)\n",
    "\n",
    "# 尝试训练模型\n",
    "print(\"开始训练...\")\n",
    "trainer.train()\n",
    "\n",
    "# 确保保存目录存在\n",
    "save_dir = \"/mnt/d/forCoding_data/Tianchi_EcommerceKG/trained_models/lora-ckpt/final\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "trainer.save_model(save_dir)\n",
    "\n",
    "print(\"训练完成，模型已保存到:\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a987f68-73f0-4348-911f-777f169cab18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78295bcf-7cb5-43a4-b73b-a1e40c31db59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786e61b2-a628-4291-9a24-76aa4ee6cf0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7838996a-39be-4e3f-b8ef-51c3eb5ece8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46931332-cfb0-4685-b518-5fe39b875af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627e1d1-d400-46f7-b877-8e3de1d67659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2902afac-a1eb-4cda-a234-0d21928cd96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a4a6db-f57a-4dc7-b19d-9a708dd6df5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9474276-f7bc-40cf-b301-f38678a2676a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9509ea-ac99-4fea-b160-c90ec7a1c5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fb3a06-9edd-4126-9214-96b35cbfc66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9486d085-1b86-4386-9838-7ac115dee39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b21673d-3e64-4e04-9802-4fbf7f24365c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42be8b12-8737-4c80-9c6d-d8d3d833ba61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07698740-0c52-424f-9ad6-252b5a33b766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA可用，将使用GPU进行训练\n",
      "GPU 0: NVIDIA GeForce RTX 4070 Ti SUPER, 显存: 15.99GB\n",
      "数据集大小: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 11745.05 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized后的数据格式: ['input_ids', 'attention_mask', 'labels']\n",
      "Input IDs示例: [105332, 112446, 44991, 23305, 40027, 9370, 113272, 3837, 100346, 36556]...\n",
      "Labels示例: [105332, 112446, 44991, 23305, 40027, 9370, 113272, 3837, 100346, 36556]...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████| 3/3 [00:26<00:00,  8.97s/it]\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU内存使用: 已分配 3.97GB, 已保留 4.46GB\n",
      "GPU内存使用: 已分配 3.98GB, 已保留 4.47GB\n",
      "GPU内存使用: 已分配 3.98GB, 已保留 4.47GB\n",
      "GPU内存使用: 已分配 3.98GB, 已保留 4.47GB\n",
      "GPU内存使用: 已分配 3.98GB, 已保留 4.47GB\n",
      "GPU内存使用: 已分配 3.98GB, 已保留 4.47GB\n",
      "GPU内存使用: 已分配 3.98GB, 已保留 4.47GB\n",
      "GPU内存使用: 已分配 3.98GB, 已保留 4.47GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='95' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 95/625 07:17 < 41:30, 0.21 it/s, Epoch 0.15/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>136.511500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>104.782400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>66.499100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>20.776400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>7.586800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.642600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.212400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.239600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.571100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU内存使用: 已分配 3.99GB, 已保留 4.48GB\n",
      "GPU内存使用: 已分配 3.99GB, 已保留 4.48GB\n",
      "GPU内存使用: 已分配 3.99GB, 已保留 4.48GB\n",
      "GPU内存使用: 已分配 3.99GB, 已保留 4.48GB\n",
      "GPU内存使用: 已分配 3.99GB, 已保留 4.48GB\n",
      "GPU内存使用: 已分配 3.99GB, 已保留 4.48GB\n",
      "GPU内存使用: 已分配 3.99GB, 已保留 4.48GB\n",
      "GPU内存使用: 已分配 3.99GB, 已保留 4.48GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/IPython/core/async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3413\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3409\u001b[39m exec_count = \u001b[38;5;28mself\u001b[39m.execution_count\n\u001b[32m   3410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3411\u001b[39m     \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3412\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[exec_count] = (\n\u001b[32m-> \u001b[39m\u001b[32m3413\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_exception_for_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror_in_exec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3414\u001b[39m     )\n\u001b[32m   3416\u001b[39m \u001b[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001b[39;00m\n\u001b[32m   3417\u001b[39m \u001b[38;5;28mself\u001b[39m.execution_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3467\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3464\u001b[39m         stb = evalue._render_traceback_()\n\u001b[32m   3465\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3466\u001b[39m         \u001b[38;5;66;03m# Otherwise, use InteractiveTB to format the traceback.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3467\u001b[39m         stb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mInteractiveTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3468\u001b[39m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   3469\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3470\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   3471\u001b[39m     \u001b[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001b[39;00m\n\u001b[32m   3472\u001b[39m     stb = traceback.format_exception(etype, evalue, tb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/IPython/core/ultratb.py:1185\u001b[39m, in \u001b[36mAutoFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1183\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1184\u001b[39m     \u001b[38;5;28mself\u001b[39m.tb = etb\n\u001b[32m-> \u001b[39m\u001b[32m1185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/IPython/core/ultratb.py:1056\u001b[39m, in \u001b[36mFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1053\u001b[39m mode = \u001b[38;5;28mself\u001b[39m.mode\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose_modes:\n\u001b[32m   1055\u001b[39m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mDocs\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1060\u001b[39m     \u001b[38;5;66;03m# return DocTB\u001b[39;00m\n\u001b[32m   1061\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DocTB(\n\u001b[32m   1062\u001b[39m         theme_name=\u001b[38;5;28mself\u001b[39m._theme_name,\n\u001b[32m   1063\u001b[39m         call_pdb=\u001b[38;5;28mself\u001b[39m.call_pdb,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1071\u001b[39m         etype, evalue, etb, tb_offset, \u001b[32m1\u001b[39m\n\u001b[32m   1072\u001b[39m     )  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/IPython/core/ultratb.py:864\u001b[39m, in \u001b[36mVerboseTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstructured_traceback\u001b[39m(\n\u001b[32m    856\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    857\u001b[39m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    861\u001b[39m     context: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m,\n\u001b[32m    862\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    863\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m     formatted_exceptions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m        \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m     termsize = \u001b[38;5;28mmin\u001b[39m(\u001b[32m75\u001b[39m, get_terminal_size()[\u001b[32m0\u001b[39m])\n\u001b[32m    869\u001b[39m     theme = theme_table[\u001b[38;5;28mself\u001b[39m._theme_name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/IPython/core/ultratb.py:776\u001b[39m, in \u001b[36mVerboseTB.format_exception_as_a_whole\u001b[39m\u001b[34m(self, etype, evalue, etb, context, tb_offset)\u001b[39m\n\u001b[32m    766\u001b[39m         frames.append(\n\u001b[32m    767\u001b[39m             theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    768\u001b[39m                 [\n\u001b[32m   (...)\u001b[39m\u001b[32m    773\u001b[39m             )\n\u001b[32m    774\u001b[39m         )\n\u001b[32m    775\u001b[39m         skipped = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m     frames.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    777\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skipped:\n\u001b[32m    778\u001b[39m     frames.append(\n\u001b[32m    779\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    780\u001b[39m             [\n\u001b[32m   (...)\u001b[39m\u001b[32m    785\u001b[39m         )\n\u001b[32m    786\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/IPython/core/ultratb.py:652\u001b[39m, in \u001b[36mVerboseTB.format_record\u001b[39m\u001b[34m(self, frame_info)\u001b[39m\n\u001b[32m    648\u001b[39m result += \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m call \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m result += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m result += theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    651\u001b[39m     _format_traceback_lines(\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m         \u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlines\u001b[49m,\n\u001b[32m    653\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name],\n\u001b[32m    654\u001b[39m         \u001b[38;5;28mself\u001b[39m.has_colors,\n\u001b[32m    655\u001b[39m         lvals_toks,\n\u001b[32m    656\u001b[39m     )\n\u001b[32m    657\u001b[39m )\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/IPython/core/tbtools.py:355\u001b[39m, in \u001b[36mFrameInfo.lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlines\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m NotOneValueFound:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDummy\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/stack_data/utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/stack_data/core.py:734\u001b[39m, in \u001b[36mFrameInfo.lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlines\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[Union[Line, LineGap, BlankLineRange]]:\n\u001b[32m    720\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    721\u001b[39m \u001b[33;03m    A list of lines to display, determined by options.\u001b[39;00m\n\u001b[32m    722\u001b[39m \u001b[33;03m    The objects yielded either have type Line, BlankLineRange\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    732\u001b[39m \u001b[33;03m    The Line objects are all within the ranges from .included_pieces.\u001b[39;00m\n\u001b[32m    733\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m     pieces = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mincluded_pieces\u001b[49m\n\u001b[32m    735\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pieces:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/stack_data/utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/stack_data/core.py:677\u001b[39m, in \u001b[36mFrameInfo.included_pieces\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;129m@cached_property\u001b[39m\n\u001b[32m    667\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mincluded_pieces\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[\u001b[38;5;28mrange\u001b[39m]:\n\u001b[32m    668\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    669\u001b[39m \u001b[33;03m    The list of pieces (ranges of lines) to display for this frame.\u001b[39;00m\n\u001b[32m    670\u001b[39m \u001b[33;03m    Consists of .executing_piece, surrounding context pieces\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    675\u001b[39m \u001b[33;03m    Always a subset of .scope_pieces.\u001b[39;00m\n\u001b[32m    676\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     scope_pieces = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscope_pieces\u001b[49m\n\u001b[32m    678\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.scope_pieces:\n\u001b[32m    679\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/stack_data/utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/stack_data/core.py:617\u001b[39m, in \u001b[36mFrameInfo.scope_pieces\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    612\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.source.pieces\n\u001b[32m    614\u001b[39m scope_start, scope_end = \u001b[38;5;28mself\u001b[39m.source.line_range(\u001b[38;5;28mself\u001b[39m.scope)\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    616\u001b[39m     piece\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m piece \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpieces\u001b[49m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m scope_start <= piece.start \u001b[38;5;129;01mand\u001b[39;00m piece.stop <= scope_end\n\u001b[32m    619\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/stack_data/utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/stack_data/core.py:101\u001b[39m, in \u001b[36mSource.pieces\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tree:\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m     98\u001b[39m         \u001b[38;5;28mrange\u001b[39m(i, i + \u001b[32m1\u001b[39m)\n\u001b[32m     99\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.lines) + \u001b[32m1\u001b[39m)\n\u001b[32m    100\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m._clean_pieces())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/stack_data/core.py:114\u001b[39m, in \u001b[36mSource._clean_pieces\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_clean_pieces\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[\u001b[38;5;28mrange\u001b[39m]:\n\u001b[32m    113\u001b[39m     pieces = \u001b[38;5;28mself\u001b[39m._raw_split_into_pieces(\u001b[38;5;28mself\u001b[39m.tree, \u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.lines) + \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     pieces = \u001b[43m[\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpieces\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# Combine overlapping pieces, i.e. consecutive pieces where the end of the first\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# is greater than the start of the second.\u001b[39;00m\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# This can happen when two statements are on the same line separated by a semicolon.\u001b[39;00m\n\u001b[32m    123\u001b[39m     new_pieces = pieces[:\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ml12/lib/python3.11/site-packages/stack_data/core.py:117\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_clean_pieces\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[\u001b[38;5;28mrange\u001b[39m]:\n\u001b[32m    113\u001b[39m     pieces = \u001b[38;5;28mself\u001b[39m._raw_split_into_pieces(\u001b[38;5;28mself\u001b[39m.tree, \u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.lines) + \u001b[32m1\u001b[39m)\n\u001b[32m    114\u001b[39m     pieces = [\n\u001b[32m    115\u001b[39m         (start, end)\n\u001b[32m    116\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m (start, end) \u001b[38;5;129;01min\u001b[39;00m pieces\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m end > start\n\u001b[32m    118\u001b[39m     ]\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# Combine overlapping pieces, i.e. consecutive pieces where the end of the first\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# is greater than the start of the second.\u001b[39;00m\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# This can happen when two statements are on the same line separated by a semicolon.\u001b[39;00m\n\u001b[32m    123\u001b[39m     new_pieces = pieces[:\u001b[32m1\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "with open(\"2.0-第一次跑通.py\", \"r\") as f:\n",
    "    js = f.read()\n",
    "    exec(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a4b48-8d6a-471c-acc2-9b0656163261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2f6211-7ecb-44f4-baad-2506c60d04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"HF_ENDPOINT\"] = 'https://hf-mirror.com'\n",
    "# os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "# os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "# os.environ['all_proxy'] = 'socks5://127.0.0.1:7890'\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# # 尝试自动检测CUDA路径，如果失败则使用CPU\n",
    "# import torch\n",
    "# try:\n",
    "#     # 尝试导入CUDA相关模块\n",
    "# torch.cuda.is_available()\n",
    "#     print(\"CUDA可用，将使用GPU进行训练\")\n",
    "# except:\n",
    "#     print(\"CUDA不可用，将使用CPU进行训练\")\n",
    "\n",
    "# import pandas as pd, openai, random\n",
    "# from datasets import load_dataset\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "# from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# model_path = \"/mnt/d/HuggingFaceModels\"\n",
    "# dataset = load_dataset(\"json\", data_files=\"/mnt/d/forCoding_data/Tianchi_EcommerceKG/preprocessedData/df_sample_full.jsonl\", split=\"train\")\n",
    "\n",
    "# # 确保数据集不为空\n",
    "# print(f\"数据集大小: {len(dataset)}\")\n",
    "# if len(dataset) == 0:\n",
    "#     raise ValueError(\"数据集为空，请检查数据文件路径是否正确\")\n",
    "\n",
    "# # 查看数据集的前几个样本\n",
    "# sample = dataset[0]\n",
    "# print(f\"数据集样本示例: {sample}\")\n",
    "\n",
    "# # 加载分词器\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-4B\", cache_dir=model_path)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# # 修改数据处理函数，确保正确设置标签\n",
    "# def tokenize(examples):\n",
    "#     texts = [\n",
    "#         f\"{inst}\\n{inp}\\n{out}\"\n",
    "#         for inst, inp, out in zip(\n",
    "#             examples[\"instruction\"],\n",
    "#             examples[\"input\"],\n",
    "#             examples[\"output\"]\n",
    "#         )\n",
    "#     ]\n",
    "#     tokenized = tokenizer(\n",
    "#         texts,\n",
    "#         truncation=True,\n",
    "#         max_length=512,\n",
    "#         padding=\"max_length\",  # 使用max_length填充而不是动态填充\n",
    "#     )\n",
    "#     # 正确设置labels，确保梯度能够流动\n",
    "#     tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "#     return tokenized\n",
    "\n",
    "# dataset = dataset.map(tokenize, batched=True, remove_columns=dataset.column_names)\n",
    "\n",
    "# # 检查tokenized后的数据集格式\n",
    "# print(f\"Tokenized后的数据格式: {list(dataset.features.keys())}\")\n",
    "# print(f\"Input IDs示例: {dataset[0]['input_ids'][:10]}...\")\n",
    "# print(f\"Labels示例: {dataset[0]['labels'][:10]}...\")\n",
    "\n",
    "# # 根据实际环境选择是否使用量化\n",
    "# try:\n",
    "#     # 配置量化参数，适合16GB显存\n",
    "#     quantization_config = BitsAndBytesConfig(\n",
    "#         load_in_4bit=True,\n",
    "#         bnb_4bit_use_double_quant=True,\n",
    "#         bnb_4bit_quant_type=\"nf4\",\n",
    "#         bnb_4bit_compute_dtype=torch.bfloat16\n",
    "#     )\n",
    "#     use_quantization = True\n",
    "# except Exception as e:\n",
    "#     print(f\"量化配置失败: {e}\")\n",
    "#     print(\"将不使用量化\")\n",
    "#     use_quantization = False\n",
    "\n",
    "# # 使用GPU和量化加载模型\n",
    "# model_kwargs = {\n",
    "#     \"cache_dir\": model_path,\n",
    "#     \"torch_dtype\": torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "#     \"device_map\": \"auto\" if torch.cuda.is_available() else None,\n",
    "#     \"trust_remote_code\": True\n",
    "# }\n",
    "\n",
    "# if use_quantization:\n",
    "#     model_kwargs[\"quantization_config\"] = quantization_config\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"Qwen/Qwen3-4B\",\n",
    "#     **model_kwargs\n",
    "# )\n",
    "\n",
    "# # 配置LoRA参数\n",
    "# lora_config = LoraConfig(\n",
    "#     task_type=TaskType.CAUSAL_LM,\n",
    "#     r=4, lora_alpha=8, lora_dropout=0.05,\n",
    "#     target_modules=[\"q_proj\", \"v_proj\"],\n",
    "#     bias=\"none\"  # 确保偏置不参与LoRA\n",
    "# )\n",
    "\n",
    "# model = get_peft_model(model, lora_config)\n",
    "\n",
    "# # 配置训练参数，优化显存使用\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./lora-ckpt\",\n",
    "#     per_device_train_batch_size=1,\n",
    "#     gradient_accumulation_steps=16,  # 增加梯度累积步数减少显存占用\n",
    "#     num_train_epochs=1,\n",
    "#     learning_rate=2e-4,\n",
    "#     fp16=torch.cuda.is_available(),      # 仅在GPU可用时开启fp16加速训练\n",
    "#     bf16=False,     # 不使用bf16\n",
    "#     optim=\"paged_adamw_32bit\",  # 使用分页优化器减少内存占用\n",
    "#     gradient_checkpointing=True,  # 启用梯度检查点节省显存\n",
    "#     save_steps=500,\n",
    "#     save_total_limit=2,  # 限制保存的checkpoint数量\n",
    "#     report_to=\"none\",  # 禁用wandb\n",
    "#     remove_unused_columns=False,  # 保留所有列以确保梯度正确传播\n",
    "#     # 添加以下参数解决梯度问题\n",
    "#     gradient_checkpointing_kwargs={\"use_reentrant\": False}\n",
    "# )\n",
    "\n",
    "# # 自定义Trainer类以确保梯度正确传播\n",
    "# class CustomTrainer(Trainer):\n",
    "#     def compute_loss(self, model, inputs, return_outputs=False):\n",
    "#         # 确保inputs包含labels，并且labels是可微分的\n",
    "#         if \"labels\" not in inputs:\n",
    "#             raise ValueError(\"输入中缺少labels\")\n",
    "        \n",
    "#         # 确保labels是tensor并且在正确的设备上\n",
    "#         inputs[\"labels\"] = torch.tensor(inputs[\"labels\"]).to(model.device)\n",
    "        \n",
    "#         outputs = model(**inputs)\n",
    "#         loss = outputs.loss\n",
    "        \n",
    "#         # 确保loss是标量并且可以微分\n",
    "#         if loss is None:\n",
    "#             # 如果模型没有自动计算loss，手动计算\n",
    "#             logits = outputs.logits\n",
    "#             labels = inputs[\"labels\"]\n",
    "#             # 使用交叉熵损失\n",
    "#             loss_fct = torch.nn.CrossEntropyLoss()\n",
    "#             # 调整logits和labels的形状以匹配CrossEntropyLoss的要求\n",
    "#             loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "        \n",
    "#         return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# # 使用自定义Trainer\n",
    "# if torch.cuda.is_available():\n",
    "#     # 在GPU上使用自定义Trainer\n",
    "#     trainer = CustomTrainer(model=model, args=training_args, train_dataset=dataset)\n",
    "# else:\n",
    "#     # 在CPU上使用标准Trainer（可能需要调整参数以减少内存使用）\n",
    "#     trainer = Trainer(model=model, args=training_args, train_dataset=dataset)\n",
    "\n",
    "# try:\n",
    "#     trainer.train()\n",
    "#     # 确保保存目录存在\n",
    "#     save_dir = \"/mnt/d/forCoding_data/Tianchi_EcommerceKG/trained_models/lora-ckpt/final\"\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "#     trainer.save_model(save_dir)\n",
    "# except Exception as e:\n",
    "#     print(f\"训练过程中出错: {e}\")\n",
    "#     # 如果训练失败，尝试使用更保守的设置\n",
    "#     print(\"尝试使用更保守的设置进行训练...\")\n",
    "    \n",
    "#     # 禁用量化和梯度检查点\n",
    "#     model = AutoModelForCausalLM.from_pretrained(\n",
    "#         \"Qwen/Qwen3-4B\",\n",
    "#         cache_dir=model_path,\n",
    "#         torch_dtype=torch.float32,  # 使用float32而不是bfloat16\n",
    "#         device_map=None,  # 不自动分配设备\n",
    "#         trust_remote_code=True\n",
    "#     )\n",
    "    \n",
    "#     model = get_peft_model(model, lora_config)\n",
    "    \n",
    "#     # 使用更保守的训练参数\n",
    "#     training_args = TrainingArguments(\n",
    "#         output_dir=\"./lora-ckpt\",\n",
    "#         per_device_train_batch_size=1,\n",
    "#         gradient_accumulation_steps=32,  # 增加梯度累积步数\n",
    "#         num_train_epochs=1,\n",
    "#         learning_rate=1e-4,\n",
    "#         fp16=False,  # 禁用fp16\n",
    "#         bf16=False,\n",
    "#         optim=\"adamw_torch\",  # 使用标准优化器\n",
    "#         gradient_checkpointing=False,  # 禁用梯度检查点\n",
    "#         save_steps=500,\n",
    "#         save_total_limit=2,\n",
    "#         report_to=\"none\",\n",
    "#         remove_unused_columns=False\n",
    "#     )\n",
    "    \n",
    "#     trainer = CustomTrainer(model=model, args=training_args, train_dataset=dataset)\n",
    "#     trainer.train()\n",
    "#     trainer.save_model(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b45da8a-0225-4f4d-8f76-25181acdb101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7dbbe6-9fc8-4e93-b6a1-607525b2d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sql = \"\"\"Error with archive /mnt/d/programs/wsl_anaconda3/pkgs/ncurses-6.5-h7934f7d_0.conda.  You probably need to delete and re-download or re-create this file.  Message was:\\n\\n\\n        Cannot extract package to a case-insensitive file system. Your install\\n        destination does not differentiate between upper and lowercase\\n        characters, and this breaks things. Try installing to a location that\\n        is case-sensitive. Windows drives are usually the culprit here - can\\n        you install to a native Unix drive, or turn on case sensitivity for\\n        this (Windows) location?\\n\\n          package location: %(package_location)s\\n          extract location: %(extract_location)s\\n        \"\"\"\n",
    "# # print(\n",
    "# #     sql\n",
    "# # ) \n",
    "\n",
    "# import os\n",
    "# os.environ[\"HF_ENDPOINT\"] = 'https://hf-mirror.com'\n",
    "# os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "# os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "# os.environ['all_proxy'] = 'socks5://127.0.0.1:7890'\n",
    "# os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "# os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda\"  # 替换为您的CUDA安装路径\n",
    "\n",
    "# import pandas as pd, openai, random\n",
    "# from datasets import load_dataset\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, BitsAndBytesConfig\n",
    "# from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# model_path = \"/mnt/d/HuggingFaceModels\"\n",
    "# dataset = load_dataset(\"json\", data_files=\"/mnt/d/forCoding_data/Tianchi_EcommerceKG/preprocessedData/df_sample_full.jsonl\", split=\"train\")\n",
    "\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-4B\", cache_dir=model_path)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "\n",
    "# def tokenize(examples):\n",
    "#     texts = [\n",
    "#         f\"{inst}\\n{inp}\\n{out}\"\n",
    "#         for inst, inp, out in zip(\n",
    "#             examples[\"instruction\"],\n",
    "#             examples[\"input\"],\n",
    "#             examples[\"output\"]\n",
    "#         )\n",
    "#     ]\n",
    "#     tokenized = tokenizer(\n",
    "#         texts,\n",
    "#         truncation=True,\n",
    "#         max_length=512,\n",
    "#         padding=False,        # 不 pad，Trainer 会动态 pad\n",
    "#     )\n",
    "#     tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "#     return tokenized\n",
    "\n",
    "# dataset = dataset.map(tokenize, batched=True, remove_columns=dataset.column_names)\n",
    "\n",
    "# import torch\n",
    "# # 配置量化参数，适合16GB显存\n",
    "# quantization_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )\n",
    "\n",
    "# # 使用GPU和量化加载模型\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"Qwen/Qwen3-4B\",\n",
    "#     cache_dir=model_path,\n",
    "#     quantization_config=quantization_config,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=\"auto\",  # 自动分配到可用的GPU\n",
    "#     trust_remote_code=True\n",
    "# )\n",
    "\n",
    "# lora_config = LoraConfig(\n",
    "#     task_type=TaskType.CAUSAL_LM,\n",
    "#     r=4, lora_alpha=8, lora_dropout=0.05,\n",
    "#     target_modules=[\"q_proj\", \"v_proj\"]\n",
    "# )\n",
    "# model = get_peft_model(model, lora_config)\n",
    "\n",
    "# # 配置训练参数，优化显存使用\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./lora-ckpt\",\n",
    "#     per_device_train_batch_size=1,\n",
    "#     gradient_accumulation_steps=16,  # 增加梯度累积步数减少显存占用\n",
    "#     num_train_epochs=1,\n",
    "#     learning_rate=2e-4,\n",
    "#     fp16=True,      # 开启fp16加速训练\n",
    "#     bf16=False,     # 不使用bf16\n",
    "#     optim=\"paged_adamw_32bit\",  # 使用分页优化器减少内存占用\n",
    "#     gradient_checkpointing=True,  # 启用梯度检查点节省显存\n",
    "#     save_steps=500,\n",
    "#     save_total_limit=2,  # 限制保存的checkpoint数量\n",
    "#     report_to=\"none\"  # 禁用wandb\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(model=model, args=training_args, train_dataset=dataset)\n",
    "# trainer.train()\n",
    "# trainer.save_model(\"/mnt/d/forCoding_data/Tianchi_EcommerceKG/trained_models/lora-ckpt/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9878bac8-1821-4df2-8eeb-b16ef44f4ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415a8c2-5b97-404b-87a2-106be825b828",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
